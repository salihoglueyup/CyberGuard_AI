"""
Groq AI Handler - CyberGuard AI
Llama 3.3 70B ile hÄ±zlÄ± ve Ã¼cretsiz AI yanÄ±tlarÄ±

Ref: https://console.groq.com/docs/quickstart
"""

import os
import logging
from typing import Optional, Dict, List
from datetime import datetime

try:
    from groq import Groq

    GROQ_AVAILABLE = True
except ImportError:
    GROQ_AVAILABLE = False
    Groq = None


class GroqHandler:
    """
    Groq AI Handler

    Desteklenen modeller:
    - llama-3.3-70b-versatile (en gÃ¼Ã§lÃ¼)
    - llama-3.1-8b-instant (en hÄ±zlÄ±)
    - mixtral-8x7b-32768 (uzun context)
    """

    AVAILABLE_MODELS = {
        "llama-3.3-70b-versatile": {
            "name": "Llama 3.3 70B",
            "description": "En gÃ¼Ã§lÃ¼ model, Ã§ok yÃ¶nlÃ¼",
            "context_window": 128000,
        },
        "llama-3.1-8b-instant": {
            "name": "Llama 3.1 8B",
            "description": "En hÄ±zlÄ± model, basit gÃ¶revler iÃ§in",
            "context_window": 128000,
        },
        "mixtral-8x7b-32768": {
            "name": "Mixtral 8x7B",
            "description": "Uzun context destekli",
            "context_window": 32768,
        },
    }

    def __init__(
        self,
        model: str = "llama-3.3-70b-versatile",
        temperature: float = 0.3,
        max_tokens: int = 4096,
        api_key: Optional[str] = None,
    ):
        """
        Groq Handler baÅŸlat

        Args:
            model: KullanÄ±lacak model
            temperature: YaratÄ±cÄ±lÄ±k seviyesi (0-1)
            max_tokens: Maksimum token sayÄ±sÄ±
            api_key: Groq API key (yoksa env'den alÄ±r)
        """
        self.logger = logging.getLogger("GroqHandler")

        if not GROQ_AVAILABLE:
            raise ImportError("groq paketi yÃ¼klÃ¼ deÄŸil! pip install groq")

        self.api_key = api_key or os.getenv("GROQ_API_KEY")
        if not self.api_key:
            raise ValueError("GROQ_API_KEY bulunamadÄ±! .env dosyasÄ±na ekleyin.")

        self.model = model
        self.temperature = temperature
        self.max_tokens = max_tokens

        # Groq client oluÅŸtur
        self.client = Groq(api_key=self.api_key)

        self.logger.info(f"âœ… Groq Handler initialized - Model: {model}")
        print(f"ğŸ¦™ Groq AI baÅŸlatÄ±ldÄ± - Model: {model}")

    def chat(
        self,
        user_message: str,
        system_prompt: Optional[str] = None,
        context: Optional[str] = None,
        history: Optional[List[Dict]] = None,
    ) -> str:
        """
        KullanÄ±cÄ± mesajÄ±na yanÄ±t ver

        Args:
            user_message: KullanÄ±cÄ± mesajÄ±
            system_prompt: Sistem promptu
            context: Ek baÄŸlam bilgisi
            history: KonuÅŸma geÃ§miÅŸi

        Returns:
            AI yanÄ±tÄ±
        """
        try:
            # MesajlarÄ± oluÅŸtur
            messages = []

            # System prompt
            if system_prompt:
                messages.append({"role": "system", "content": system_prompt})
            else:
                messages.append(
                    {"role": "system", "content": self._get_default_system_prompt()}
                )

            # GeÃ§miÅŸ mesajlar
            if history:
                for msg in history[-10:]:  # Son 10 mesaj
                    messages.append(
                        {
                            "role": msg.get("role", "user"),
                            "content": msg.get("content", ""),
                        }
                    )

            # Context varsa ekle
            full_message = user_message
            if context:
                full_message = f"{context}\n\n---\n\nKullanÄ±cÄ± Sorusu: {user_message}"

            messages.append({"role": "user", "content": full_message})

            self.logger.info(f"ğŸ¦™ Groq API Ã§aÄŸrÄ±lÄ±yor... ({len(messages)} mesaj)")

            # API Ã§aÄŸrÄ±sÄ±
            response = self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                temperature=self.temperature,
                max_tokens=self.max_tokens,
            )

            # YanÄ±tÄ± al
            answer = response.choices[0].message.content

            self.logger.info(f"âœ… Groq yanÄ±t alÄ±ndÄ± ({len(answer)} karakter)")

            return answer

        except Exception as e:
            self.logger.error(f"âŒ Groq API Error: {e}")
            return f"ÃœzgÃ¼nÃ¼m, bir hata oluÅŸtu: {str(e)}"

    def _get_default_system_prompt(self) -> str:
        """VarsayÄ±lan sistem promptu - model bilgileri dahil"""

        # Model bilgilerini al
        model_info = ""
        try:
            from src.chatbot.model_integration import get_integration

            integration = get_integration()

            if integration.training_results:
                model_info = "\n\nğŸ“Š MEVCUT MODEL SONUÃ‡LARI:\n"
                for name, results in list(integration.training_results.items())[:5]:
                    if isinstance(results, dict):
                        acc = results.get("accuracy", 0)
                        if isinstance(acc, float) and acc < 1:
                            acc *= 100
                        model_info += f"  - {name}: %{acc:.2f} accuracy\n"

                model_count = len(integration.get_available_models())
                model_info += f"\nğŸ“¦ Toplam {model_count} eÄŸitilmiÅŸ model var."
        except:
            pass

        return f"""Sen CyberGuard AI'Ä±n geliÅŸmiÅŸ siber gÃ¼venlik asistanÄ±sÄ±n.

ğŸ¯ TEMEL GÃ–REVLERÄ°N:
1. Siber gÃ¼venlik sorularÄ±nÄ± uzman dÃ¼zeyinde yanÄ±tla
2. IDS/IPS modelleri hakkÄ±nda bilgi ver
3. SaldÄ±rÄ± tespiti ve analizi yap
4. Makine Ã¶ÄŸrenimi modellerini aÃ§Ä±kla
5. Savunma stratejileri Ã¶ner

ğŸ¤– MEVCUT SÄ°STEM DURUMU:
- SSA-LSTMIDS modeli aktif (makale ile birebir)
- CICIDS2017 dataset ile eÄŸitildi
- DDoS ve PortScan modelleri hazÄ±r
- Real-time IDS mevcut
{model_info}

ğŸ“ CEVAP KURALLARI:
- Her zaman TÃ¼rkÃ§e yanÄ±t ver
- Teknik ama anlaÅŸÄ±lÄ±r ol
- Somut ve uygulanabilir Ã¶neriler sun
- Emoji kullan ama abartma
- Kod Ã¶rnekleri gÃ¶ster gerekirse
- Tablo formatÄ±nÄ± kullan (markdown)
- KarÅŸÄ±laÅŸtÄ±rmalÄ± bilgi ver

ğŸ”§ Ã–NEMLÄ° BÄ°LGÄ°LER:
- Makale: SSA-LSTMIDS (Conv1D + LSTM)
- Parametreler: Conv1D(30), LSTM(120), Dense(512)
- CICIDS2017 accuracy: %99.96
- DDoS model accuracy: %99.62

Åu anki tarih: """ + datetime.now().strftime(
            "%Y-%m-%d %H:%M"
        )

    def get_model_info(self) -> Dict:
        """Model bilgilerini dÃ¶ndÃ¼r"""
        model_info = self.AVAILABLE_MODELS.get(self.model, {})
        return {
            "provider": "groq",
            "model": self.model,
            "name": model_info.get("name", self.model),
            "description": model_info.get("description", ""),
            "context_window": model_info.get("context_window", 0),
            "temperature": self.temperature,
            "max_tokens": self.max_tokens,
        }

    @classmethod
    def list_models(cls) -> List[Dict]:
        """Mevcut modelleri listele"""
        return [
            {"id": model_id, **info} for model_id, info in cls.AVAILABLE_MODELS.items()
        ]


# Test
if __name__ == "__main__":
    from dotenv import load_dotenv

    load_dotenv()

    print("ğŸ§ª Groq Handler Test\n")

    try:
        handler = GroqHandler()

        print("ğŸ“‹ Mevcut modeller:")
        for model in handler.list_models():
            print(f"   - {model['id']}: {model['name']}")

        print("\nğŸ’¬ Test mesajÄ± gÃ¶nderiliyor...")
        response = handler.chat("Merhaba! Bana kendini tanÄ±t.")
        print(f"\nğŸ¦™ YanÄ±t:\n{response}")

    except Exception as e:
        print(f"âŒ Hata: {e}")
