"""
Groq AI Handler - CyberGuard AI
Llama 3.3 70B ile hÄ±zlÄ± ve Ã¼cretsiz AI yanÄ±tlarÄ±

Enhanced Features:
- Few-Shot Examples
- Conversation Memory
- RAG Integration
- Structured Response Format

Ref: https://console.groq.com/docs/quickstart
"""

import os
import logging
from typing import Optional, Dict, List
from datetime import datetime

try:
    from groq import Groq

    GROQ_AVAILABLE = True
except ImportError:
    GROQ_AVAILABLE = False
    Groq = None


# Few-Shot Examples - AI'a Ã¶rnek yanÄ±tlar
FEW_SHOT_EXAMPLES = [
    {"role": "user", "content": "SeÃ§ili model hakkÄ±nda bilgi ver"},
    {
        "role": "assistant",
        "content": """## ğŸ¤– SeÃ§ili Model Analizi

### ğŸ“Š Performans Metrikleri
| Metrik | DeÄŸer | DeÄŸerlendirme |
|--------|-------|---------------|
| Accuracy | 96.7% | âœ… MÃ¼kemmel |
| Precision | 96.9% | âœ… MÃ¼kemmel |
| Recall | 96.7% | âœ… MÃ¼kemmel |
| F1-Score | 96.7% | âœ… MÃ¼kemmel |

### ğŸ‹ï¸ EÄŸitim Bilgileri
- **Train Samples**: 70,000
- **Framework**: TensorFlow/Keras
- **Mimari**: Deep Neural Network

### ğŸ’¡ DeÄŸerlendirme
Model yÃ¼ksek performans gÃ¶steriyor. Ã–zellikle Precision deÄŸeri, false positive oranÄ±nÄ±n dÃ¼ÅŸÃ¼k olduÄŸunu gÃ¶steriyor.

### ğŸ”§ Ã–neriler
1. Val Accuracy Ã¶lÃ§Ã¼mÃ¼ yapÄ±lmalÄ±
2. Daha fazla veriyle fine-tuning dÃ¼ÅŸÃ¼nÃ¼lebilir
3. Confusion matrix analizi yapÄ±lmalÄ±""",
    },
    {"role": "user", "content": "SaldÄ±rÄ± istatistiklerini analiz et"},
    {
        "role": "assistant",
        "content": """## ğŸ“Š SaldÄ±rÄ± Ä°statistikleri Analizi

### ğŸ”¢ Genel Ã–zet
| Metrik | DeÄŸer |
|--------|-------|
| Toplam SaldÄ±rÄ± | 1,000,500 |
| Engellenen | 639,684 (%63.9) |
| Tespit Edilen | 360,816 (%36.1) |

### ğŸ¯ Severity DaÄŸÄ±lÄ±mÄ±
- ğŸ”´ **Critical**: 201,898 (%20.2) - ACÄ°L Ã¶nlem gerekli
- ğŸŸ  **High**: 399,312 (%39.9) - YÃ¼ksek risk
- ğŸŸ¡ **Medium**: 298,310 (%29.8) - Orta risk
- ğŸŸ¢ **Low**: 100,980 (%10.1) - DÃ¼ÅŸÃ¼k risk

### ğŸ”¥ En SÄ±k SaldÄ±rÄ± Tipleri
1. **DDoS**: 201,621 - AÄŸ yoÄŸunluÄŸu saldÄ±rÄ±larÄ±
2. **XSS**: 200,378 - Web uygulama zafiyetleri
3. **SQL Injection**: 200,223 - VeritabanÄ± saldÄ±rÄ±larÄ±

### âš ï¸ Risk DeÄŸerlendirmesi
Kritik ve yÃ¼ksek seviyeli saldÄ±rÄ±lar toplam %60'Ä± oluÅŸturuyor - ACÄ°L aksiyon gerekli!

### ğŸ’¡ Savunma Ã–nerileri
1. **WAF GÃ¼Ã§lendirme** - XSS ve SQL Injection iÃ§in
2. **DDoS Koruma** - CDN ve rate limiting
3. **IDS/IPS** - Anomali tespiti
4. **Log Analizi** - SIEM entegrasyonu
5. **EÄŸitim** - Phishing farkÄ±ndalÄ±ÄŸÄ±""",
    },
]


class GroqHandler:
    """
    Groq AI Handler - Enhanced Version

    Features:
    - Few-Shot Examples for better responses
    - Conversation history support
    - RAG integration ready
    """

    AVAILABLE_MODELS = {
        "llama-3.3-70b-versatile": {
            "name": "Llama 3.3 70B",
            "description": "En gÃ¼Ã§lÃ¼ model, Ã§ok yÃ¶nlÃ¼",
            "context_window": 128000,
        },
        "llama-3.1-8b-instant": {
            "name": "Llama 3.1 8B",
            "description": "En hÄ±zlÄ± model, basit gÃ¶revler iÃ§in",
            "context_window": 128000,
        },
        "mixtral-8x7b-32768": {
            "name": "Mixtral 8x7B",
            "description": "Uzun context destekli",
            "context_window": 32768,
        },
    }

    def __init__(
        self,
        model: str = "llama-3.3-70b-versatile",
        temperature: float = 0.3,
        max_tokens: int = 4096,
        api_key: Optional[str] = None,
    ):
        """
        Groq Handler baÅŸlat

        Args:
            model: KullanÄ±lacak model
            temperature: YaratÄ±cÄ±lÄ±k seviyesi (0-1)
            max_tokens: Maksimum token sayÄ±sÄ±
            api_key: Groq API key (yoksa env'den alÄ±r)
        """
        self.logger = logging.getLogger("GroqHandler")

        if not GROQ_AVAILABLE:
            raise ImportError("groq paketi yÃ¼klÃ¼ deÄŸil! pip install groq")

        self.api_key = api_key or os.getenv("GROQ_API_KEY")
        if not self.api_key:
            raise ValueError("GROQ_API_KEY bulunamadÄ±! .env dosyasÄ±na ekleyin.")

        self.model = model
        self.temperature = temperature
        self.max_tokens = max_tokens

        # Conversation history (son 10 mesaj)
        self.conversation_history: List[Dict] = []
        self.max_history = 10

        # Groq client oluÅŸtur
        self.client = Groq(api_key=self.api_key)

        self.logger.info(f"âœ… Groq Handler initialized - Model: {model}")
        print(f"ğŸ¦™ Groq AI baÅŸlatÄ±ldÄ± - Model: {model}")

    def chat(
        self,
        user_message: str,
        system_prompt: Optional[str] = None,
        context: Optional[str] = None,
        history: Optional[List[Dict]] = None,
    ) -> str:
        """
        KullanÄ±cÄ± mesajÄ±na yanÄ±t ver

        Args:
            user_message: KullanÄ±cÄ± mesajÄ±
            system_prompt: Sistem promptu
            context: Ek baÄŸlam bilgisi
            history: KonuÅŸma geÃ§miÅŸi

        Returns:
            AI yanÄ±tÄ±
        """
        try:
            # MesajlarÄ± oluÅŸtur
            messages = []

            # System prompt
            if system_prompt:
                messages.append({"role": "system", "content": system_prompt})
            else:
                messages.append(
                    {"role": "system", "content": self._get_default_system_prompt()}
                )

            # Few-Shot Examples ekle (Ã¶rnek yanÄ±tlar)
            for example in FEW_SHOT_EXAMPLES:
                messages.append(example)

            # Conversation history (session memory)
            if self.conversation_history:
                for msg in self.conversation_history[-self.max_history :]:
                    messages.append(
                        {
                            "role": msg.get("role", "user"),
                            "content": msg.get("content", ""),
                        }
                    )

            # External history varsa ekle
            if history:
                for msg in history[-5:]:  # Son 5 mesaj
                    messages.append(
                        {
                            "role": msg.get("role", "user"),
                            "content": msg.get("content", ""),
                        }
                    )

            # Context varsa ekle
            full_message = user_message
            if context:
                full_message = f"""ğŸ“‹ GÃœNCEL VERÄ°LER:
{context}

---

â“ KULLANICI SORUSU: {user_message}

âš ï¸ Ã–NEMLÄ°: YukarÄ±daki verileri MUTLAKA kullan ve referans ver. Tablolarla ve baÅŸlÄ±klarla yanÄ±t ver."""

            messages.append({"role": "user", "content": full_message})

            self.logger.info(f"ğŸ¦™ Groq API Ã§aÄŸrÄ±lÄ±yor... ({len(messages)} mesaj)")

            # API Ã§aÄŸrÄ±sÄ±
            response = self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                temperature=self.temperature,
                max_tokens=self.max_tokens,
            )

            # YanÄ±tÄ± al
            answer = response.choices[0].message.content

            # Conversation history'e ekle
            self.conversation_history.append({"role": "user", "content": user_message})
            self.conversation_history.append({"role": "assistant", "content": answer})

            # Max history'yi aÅŸmasÄ±n
            if len(self.conversation_history) > self.max_history * 2:
                self.conversation_history = self.conversation_history[
                    -self.max_history * 2 :
                ]

            self.logger.info(f"âœ… Groq yanÄ±t alÄ±ndÄ± ({len(answer)} karakter)")

            return answer

        except Exception as e:
            self.logger.error(f"âŒ Groq API Error: {e}")
            return f"ÃœzgÃ¼nÃ¼m, bir hata oluÅŸtu: {str(e)}"

    def _get_default_system_prompt(self) -> str:
        """VarsayÄ±lan sistem promptu"""
        return """Sen CyberGuard AI'Ä±n uzman siber gÃ¼venlik asistanÄ±sÄ±n.

ğŸ¯ ANA GÃ–REVLERÄ°N:
1. Siber gÃ¼venlik sorularÄ±nÄ± DETAYLI yanÄ±tla
2. Tehdit analizleri yap ve somut verilerle destekle
3. Savunma Ã¶nerileri sun (en az 5 Ã¶neri)
4. SaldÄ±rÄ± verilerini yorumla ve trend analizi yap
5. SeÃ§ili ML model hakkÄ±nda detaylÄ± bilgi ver

âš ï¸ Ã–NEMLÄ° - BÄ°RLEÅÄ°K ANALÄ°Z:
Her yanÄ±tta ÅŸu bilgileri BÄ°RLÄ°KTE sun:
1. SEÃ‡Ä°LÄ° MODEL ANALÄ°ZÄ° (Accuracy, Precision, Recall, F1, eÄŸitim bilgileri)
2. VERÄ°TABANI SALDIRI ANALÄ°ZÄ° (istatistikler, daÄŸÄ±lÄ±mlar)
3. BAÄLANTI KURMA (model performansÄ± ile saldÄ±rÄ± verilerini iliÅŸkilendir)
4. SAVUNMA Ã–NERÄ°LERÄ° (en az 5 Ã¶neri)

ğŸ“‹ YANITLAMA KURALLARI:
- TÃ¼rkÃ§e yanÄ±t ver
- DETAYLI ve KAPSAMLI yanÄ±tlar ver (en az 400 kelime)
- Context'teki TÃœM bilgileri kullan
- Model bilgileri varsa MUTLAKA yanÄ±tta yer ver
- SaldÄ±rÄ± istatistikleri varsa MUTLAKA yanÄ±tta yer ver
- Her ikisini de iliÅŸkilendirerek analiz et
- SayÄ±larÄ± ve istatistikleri vurgula
- BaÅŸlÄ±klar ve maddeler kullan

ğŸ“Š YANIT YAPISI:
1. **SeÃ§ili Model Ã–zeti** - Model adÄ±, metrikler, eÄŸitim bilgileri
2. **SaldÄ±rÄ± Ä°statistikleri** - Toplam, daÄŸÄ±lÄ±m, trendler
3. **Model-SaldÄ±rÄ± Ä°liÅŸkisi** - Model bu saldÄ±rÄ±larÄ± ne kadar etkili tespit eder?
4. **Risk DeÄŸerlendirmesi** - Mevcut durum analizi
5. **Savunma Ã–nerileri** - En az 5 somut Ã¶neri

ğŸ¤– MODEL HAKKINDA:
- TÃ¼m metrikleri (Accuracy, Precision, Recall, F1) aÃ§Ä±kla ve yorumla
- EÄŸitim konfigÃ¼rasyonunu (samples, epochs, layers) yorumla
- Modelin gÃ¼Ã§lÃ¼ ve zayÄ±f yÃ¶nlerini analiz et
- SaldÄ±rÄ± verileriyle karÅŸÄ±laÅŸtÄ±r

Åu anki tarih: """ + datetime.now().strftime(
            "%Y-%m-%d %H:%M"
        )

    def get_model_info(self) -> Dict:
        """Model bilgilerini dÃ¶ndÃ¼r"""
        model_info = self.AVAILABLE_MODELS.get(self.model, {})
        return {
            "provider": "groq",
            "model": self.model,
            "name": model_info.get("name", self.model),
            "description": model_info.get("description", ""),
            "context_window": model_info.get("context_window", 0),
            "temperature": self.temperature,
            "max_tokens": self.max_tokens,
        }

    @classmethod
    def list_models(cls) -> List[Dict]:
        """Mevcut modelleri listele"""
        return [
            {"id": model_id, **info} for model_id, info in cls.AVAILABLE_MODELS.items()
        ]


# Test
if __name__ == "__main__":
    from dotenv import load_dotenv

    load_dotenv()

    print("ğŸ§ª Groq Handler Test\n")

    try:
        handler = GroqHandler()

        print("ğŸ“‹ Mevcut modeller:")
        for model in handler.list_models():
            print(f"   - {model['id']}: {model['name']}")

        print("\nğŸ’¬ Test mesajÄ± gÃ¶nderiliyor...")
        response = handler.chat("Merhaba! Bana kendini tanÄ±t.")
        print(f"\nğŸ¦™ YanÄ±t:\n{response}")

    except Exception as e:
        print(f"âŒ Hata: {e}")
