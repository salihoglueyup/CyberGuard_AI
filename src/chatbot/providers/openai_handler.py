"""
OpenAI Handler - CyberGuard AI
==============================

GPT-4, GPT-4o, GPT-4-turbo desteÄŸi.

Ã–zellikler:
    - Streaming responses
    - Function calling
    - Vision (gÃ¶rsel analiz)
"""

import os
import logging
from typing import Optional, Dict, List, Any, Generator
from datetime import datetime

try:
    from openai import OpenAI

    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False
    OpenAI = None

logger = logging.getLogger("OpenAIHandler")


class OpenAIHandler:
    """
    OpenAI API Handler

    Desteklenen modeller:
    - gpt-4o (en yeni, multimodal)
    - gpt-4-turbo (hÄ±zlÄ±)
    - gpt-4 (gÃ¼Ã§lÃ¼)
    - gpt-3.5-turbo (ekonomik)
    """

    AVAILABLE_MODELS = {
        "gpt-4o": {
            "name": "GPT-4o",
            "description": "En yeni, multimodal (gÃ¶rsel + metin)",
            "context_window": 128000,
            "supports_vision": True,
        },
        "gpt-4-turbo": {
            "name": "GPT-4 Turbo",
            "description": "HÄ±zlÄ± ve gÃ¼Ã§lÃ¼",
            "context_window": 128000,
            "supports_vision": True,
        },
        "gpt-4": {
            "name": "GPT-4",
            "description": "En gÃ¼Ã§lÃ¼ reasoning",
            "context_window": 8192,
            "supports_vision": False,
        },
        "gpt-3.5-turbo": {
            "name": "GPT-3.5 Turbo",
            "description": "HÄ±zlÄ± ve ekonomik",
            "context_window": 16385,
            "supports_vision": False,
        },
    }

    def __init__(
        self,
        model: str = "gpt-4o",
        temperature: float = 0.3,
        max_tokens: int = 4096,
        api_key: Optional[str] = None,
    ):
        """
        OpenAI Handler baÅŸlat

        Args:
            model: KullanÄ±lacak model
            temperature: YaratÄ±cÄ±lÄ±k seviyesi (0-1)
            max_tokens: Maksimum token sayÄ±sÄ±
            api_key: OpenAI API key (yoksa env'den alÄ±r)
        """
        self.logger = logging.getLogger("OpenAIHandler")

        if not OPENAI_AVAILABLE:
            raise ImportError("openai paketi yÃ¼klÃ¼ deÄŸil! pip install openai")

        self.api_key = api_key or os.getenv("OPENAI_API_KEY")
        if not self.api_key:
            raise ValueError("OPENAI_API_KEY bulunamadÄ±! .env dosyasÄ±na ekleyin.")

        self.model = model
        self.temperature = temperature
        self.max_tokens = max_tokens

        # OpenAI client
        self.client = OpenAI(api_key=self.api_key)

        self.logger.info(f"âœ… OpenAI Handler initialized - Model: {model}")
        print(f"ğŸ§  OpenAI baÅŸlatÄ±ldÄ± - Model: {model}")

    def chat(
        self,
        user_message: str,
        system_prompt: Optional[str] = None,
        context: Optional[str] = None,
        history: Optional[List[Dict]] = None,
        stream: bool = False,
    ) -> str:
        """
        KullanÄ±cÄ± mesajÄ±na yanÄ±t ver

        Args:
            user_message: KullanÄ±cÄ± mesajÄ±
            system_prompt: Sistem promptu
            context: Ek baÄŸlam bilgisi
            history: KonuÅŸma geÃ§miÅŸi
            stream: Streaming response

        Returns:
            AI yanÄ±tÄ±
        """
        try:
            messages = []

            # System prompt
            if system_prompt:
                messages.append({"role": "system", "content": system_prompt})
            else:
                messages.append(
                    {"role": "system", "content": self._get_default_system_prompt()}
                )

            # History
            if history:
                for msg in history[-10:]:
                    messages.append(
                        {
                            "role": msg.get("role", "user"),
                            "content": msg.get("content", ""),
                        }
                    )

            # Context + user message
            full_message = user_message
            if context:
                full_message = f"{context}\n\n---\n\nKullanÄ±cÄ± Sorusu: {user_message}"

            messages.append({"role": "user", "content": full_message})

            self.logger.info(f"ğŸ§  OpenAI API Ã§aÄŸrÄ±lÄ±yor... ({len(messages)} mesaj)")

            if stream:
                return self._stream_response(messages)

            # Non-streaming
            response = self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                temperature=self.temperature,
                max_tokens=self.max_tokens,
            )

            answer = response.choices[0].message.content
            self.logger.info(f"âœ… OpenAI yanÄ±t alÄ±ndÄ± ({len(answer)} karakter)")

            return answer

        except Exception as e:
            self.logger.error(f"âŒ OpenAI API Error: {e}")
            return f"ÃœzgÃ¼nÃ¼m, bir hata oluÅŸtu: {str(e)}"

    def _stream_response(self, messages: List[Dict]) -> Generator[str, None, None]:
        """Streaming response"""
        try:
            stream = self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                temperature=self.temperature,
                max_tokens=self.max_tokens,
                stream=True,
            )

            for chunk in stream:
                if chunk.choices[0].delta.content:
                    yield chunk.choices[0].delta.content

        except Exception as e:
            yield f"Hata: {str(e)}"

    def chat_with_vision(
        self,
        user_message: str,
        image_url: str,
        system_prompt: Optional[str] = None,
    ) -> str:
        """
        GÃ¶rsel ile chat (GPT-4o, GPT-4-turbo)

        Args:
            user_message: KullanÄ±cÄ± mesajÄ±
            image_url: GÃ¶rsel URL veya base64
            system_prompt: Sistem promptu
        """
        if not self.AVAILABLE_MODELS.get(self.model, {}).get("supports_vision"):
            return "Bu model gÃ¶rsel analizi desteklemiyor. GPT-4o veya GPT-4-turbo kullanÄ±n."

        try:
            messages = []

            if system_prompt:
                messages.append({"role": "system", "content": system_prompt})

            messages.append(
                {
                    "role": "user",
                    "content": [
                        {"type": "text", "text": user_message},
                        {"type": "image_url", "image_url": {"url": image_url}},
                    ],
                }
            )

            response = self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                max_tokens=self.max_tokens,
            )

            return response.choices[0].message.content

        except Exception as e:
            return f"GÃ¶rsel analiz hatasÄ±: {str(e)}"

    def _get_default_system_prompt(self) -> str:
        """VarsayÄ±lan sistem promptu"""
        return f"""Sen CyberGuard AI'Ä±n geliÅŸmiÅŸ siber gÃ¼venlik asistanÄ±sÄ±n.

ğŸ¯ TEMEL GÃ–REVLERÄ°N:
1. Siber gÃ¼venlik sorularÄ±nÄ± uzman dÃ¼zeyinde yanÄ±tla
2. SaldÄ±rÄ± tespiti ve analizi yap
3. Savunma stratejileri Ã¶ner
4. Kod Ã¶rnekleri ve YARA kurallarÄ± Ã¼ret
5. MITRE ATT&CK mapping yap

ğŸ“ CEVAP KURALLARI:
- Her zaman TÃ¼rkÃ§e yanÄ±t ver
- Teknik ama anlaÅŸÄ±lÄ±r ol
- Somut ve uygulanabilir Ã¶neriler sun
- Kod Ã¶rnekleri gÃ¶ster gerekirse
- Tablo formatÄ±nÄ± kullan (markdown)

Åu anki tarih: {datetime.now().strftime('%Y-%m-%d %H:%M')}"""

    def get_model_info(self) -> Dict:
        """Model bilgilerini dÃ¶ndÃ¼r"""
        model_info = self.AVAILABLE_MODELS.get(self.model, {})
        return {
            "provider": "openai",
            "model": self.model,
            "name": model_info.get("name", self.model),
            "description": model_info.get("description", ""),
            "context_window": model_info.get("context_window", 0),
            "supports_vision": model_info.get("supports_vision", False),
            "temperature": self.temperature,
            "max_tokens": self.max_tokens,
        }

    @classmethod
    def list_models(cls) -> List[Dict]:
        """Mevcut modelleri listele"""
        return [
            {"id": model_id, **info} for model_id, info in cls.AVAILABLE_MODELS.items()
        ]

    @staticmethod
    def is_available() -> bool:
        """OpenAI kullanÄ±labilir mi?"""
        return OPENAI_AVAILABLE and bool(os.getenv("OPENAI_API_KEY"))


# Test
if __name__ == "__main__":
    from dotenv import load_dotenv

    load_dotenv()

    print("ğŸ§ª OpenAI Handler Test\n")

    if not OpenAIHandler.is_available():
        print("âŒ OpenAI API key bulunamadÄ±!")
    else:
        try:
            handler = OpenAIHandler(model="gpt-4o")

            print("ğŸ“‹ Mevcut modeller:")
            for model in handler.list_models():
                print(f"   - {model['id']}: {model['name']}")

            print("\nğŸ’¬ Test mesajÄ± gÃ¶nderiliyor...")
            response = handler.chat("Merhaba! Kendini tanÄ±t.")
            print(f"\nğŸ§  YanÄ±t:\n{response}")

        except Exception as e:
            print(f"âŒ Hata: {e}")
