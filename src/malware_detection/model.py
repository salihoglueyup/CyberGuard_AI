"""
Malware Detection Model - CyberGuard AI
Gradient Boosting + Neural Network tabanlƒ± malware tespiti

Dosya Yolu: src/malware_detection/model.py
"""

import os
import json
import pickle
import numpy as np
from typing import Dict, List, Tuple, Optional
from datetime import datetime

# ML imports
try:
    from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier
    from sklearn.preprocessing import StandardScaler
    SKLEARN_AVAILABLE = True
except ImportError:
    SKLEARN_AVAILABLE = False
    print("‚ö†Ô∏è scikit-learn y√ºkl√º deƒüil")

try:
    import tensorflow as tf
    from tensorflow import keras
    TF_AVAILABLE = True
except ImportError:
    TF_AVAILABLE = False
    print("‚ö†Ô∏è TensorFlow y√ºkl√º deƒüil")


class MalwareDetectionModel:
    """
    Malware tespit modeli
    
    √ñzellikler:
    - Gradient Boosting classifier
    - Opsiyonel Neural Network
    - Ensemble prediction
    - Model kaydetme/y√ºkleme
    """
    
    # Sƒ±nƒ±f isimleri
    CLASS_NAMES = ['benign', 'malware']
    
    def __init__(
        self,
        model_type: str = 'gradient_boosting',
        use_neural_network: bool = False
    ):
        """
        Args:
            model_type: 'gradient_boosting' veya 'random_forest'
            use_neural_network: NN de kullan
        """
        self.model_type = model_type
        self.use_neural_network = use_neural_network and TF_AVAILABLE
        
        self.scaler = StandardScaler() if SKLEARN_AVAILABLE else None
        self.classifier = None
        self.neural_network = None
        self.is_trained = False
        
        # Model t√ºr√ºn√º se√ß
        if SKLEARN_AVAILABLE:
            if model_type == 'gradient_boosting':
                self.classifier = GradientBoostingClassifier(
                    n_estimators=100,
                    max_depth=5,
                    learning_rate=0.1,
                    random_state=42
                )
            elif model_type == 'random_forest':
                self.classifier = RandomForestClassifier(
                    n_estimators=100,
                    max_depth=10,
                    random_state=42
                )
        
        print(f"ü¶† Malware Detection Model ba≈ülatƒ±ldƒ±")
        print(f"   Model tipi: {model_type}")
        print(f"   Neural Network: {'Evet' if self.use_neural_network else 'Hayƒ±r'}")
    
    def build_neural_network(self, input_dim: int) -> None:
        """
        Neural network olu≈ütur
        
        Args:
            input_dim: Girdi boyutu
        """
        if not TF_AVAILABLE:
            return
        
        self.neural_network = keras.Sequential([
            keras.layers.Dense(64, activation='relu', input_shape=(input_dim,)),
            keras.layers.BatchNormalization(),
            keras.layers.Dropout(0.3),
            
            keras.layers.Dense(32, activation='relu'),
            keras.layers.BatchNormalization(),
            keras.layers.Dropout(0.2),
            
            keras.layers.Dense(16, activation='relu'),
            keras.layers.Dense(1, activation='sigmoid')
        ])
        
        self.neural_network.compile(
            optimizer='adam',
            loss='binary_crossentropy',
            metrics=['accuracy']
        )
        
        print(f"‚úÖ Neural Network olu≈üturuldu (input_dim={input_dim})")
    
    def train(
        self,
        X: np.ndarray,
        y: np.ndarray,
        validation_split: float = 0.2,
        epochs: int = 50,
        batch_size: int = 32
    ) -> Dict:
        """
        Modeli eƒüit
        
        Args:
            X: √ñzellik matrisi
            y: Etiketler (0=benign, 1=malware)
            validation_split: Validation oranƒ±
            epochs: NN epochs
            batch_size: NN batch size
            
        Returns:
            Eƒüitim sonu√ßlarƒ±
        """
        if not SKLEARN_AVAILABLE:
            raise RuntimeError("scikit-learn y√ºkl√º deƒüil!")
        
        print(f"\nüéØ Eƒüitim ba≈ülƒ±yor...")
        print(f"   Samples: {len(X)}")
        print(f"   Features: {X.shape[1]}")
        
        results = {}
        
        # Scaler fit
        X_scaled = self.scaler.fit_transform(X)
        
        # Gradient Boosting / Random Forest
        print(f"\nüìä {self.model_type} eƒüitiliyor...")
        self.classifier.fit(X_scaled, y)
        
        train_score = self.classifier.score(X_scaled, y)
        results['classifier_accuracy'] = train_score
        print(f"   Training accuracy: {train_score:.4f}")
        
        # Neural Network
        if self.use_neural_network:
            print(f"\nüß† Neural Network eƒüitiliyor...")
            self.build_neural_network(X.shape[1])
            
            history = self.neural_network.fit(
                X_scaled, y,
                validation_split=validation_split,
                epochs=epochs,
                batch_size=batch_size,
                verbose=0
            )
            
            results['nn_accuracy'] = history.history['accuracy'][-1]
            results['nn_val_accuracy'] = history.history['val_accuracy'][-1]
            print(f"   NN accuracy: {results['nn_accuracy']:.4f}")
            print(f"   NN val_accuracy: {results['nn_val_accuracy']:.4f}")
        
        self.is_trained = True
        results['trained_at'] = datetime.now().isoformat()
        
        print(f"\n‚úÖ Eƒüitim tamamlandƒ±!")
        
        return results
    
    def predict(self, X: np.ndarray, return_proba: bool = False) -> np.ndarray:
        """
        Tahmin yap
        
        Args:
            X: √ñzellik matrisi
            return_proba: Olasƒ±lƒ±k d√∂nd√ºr
            
        Returns:
            Tahminler
        """
        if not self.is_trained:
            raise RuntimeError("Model hen√ºz eƒüitilmedi!")
        
        X_scaled = self.scaler.transform(X)
        
        if return_proba:
            proba_gb = self.classifier.predict_proba(X_scaled)[:, 1]
            
            if self.use_neural_network and self.neural_network:
                proba_nn = self.neural_network.predict(X_scaled, verbose=0).flatten()
                # Ensemble: ortalama
                return (proba_gb + proba_nn) / 2
            
            return proba_gb
        else:
            pred_gb = self.classifier.predict(X_scaled)
            
            if self.use_neural_network and self.neural_network:
                proba_nn = self.neural_network.predict(X_scaled, verbose=0).flatten()
                pred_nn = (proba_nn > 0.5).astype(int)
                # Ensemble: √ßoƒüunluk
                return ((pred_gb + pred_nn) > 0).astype(int)
            
            return pred_gb
    
    def predict_single(self, features: List[float]) -> Dict:
        """
        Tek dosya i√ßin tahmin
        
        Args:
            features: √ñzellik listesi
            
        Returns:
            Tahmin sonucu
        """
        X = np.array([features])
        
        proba = self.predict(X, return_proba=True)[0]
        prediction = 1 if proba > 0.5 else 0
        
        return {
            'prediction': self.CLASS_NAMES[prediction],
            'is_malware': bool(prediction),
            'confidence': float(proba if prediction == 1 else 1 - proba),
            'malware_probability': float(proba)
        }
    
    def save(self, model_dir: str) -> str:
        """
        Modeli kaydet
        
        Args:
            model_dir: Kayƒ±t dizini
            
        Returns:
            Kayƒ±t yolu
        """
        os.makedirs(model_dir, exist_ok=True)
        
        # Classifier
        classifier_path = os.path.join(model_dir, 'classifier.pkl')
        with open(classifier_path, 'wb') as f:
            pickle.dump(self.classifier, f)
        
        # Scaler
        scaler_path = os.path.join(model_dir, 'scaler.pkl')
        with open(scaler_path, 'wb') as f:
            pickle.dump(self.scaler, f)
        
        # Neural Network
        if self.use_neural_network and self.neural_network:
            nn_path = os.path.join(model_dir, 'neural_network.h5')
            self.neural_network.save(nn_path)
        
        # Metadata
        metadata = {
            'model_type': self.model_type,
            'use_neural_network': self.use_neural_network,
            'is_trained': self.is_trained,
            'saved_at': datetime.now().isoformat()
        }
        
        with open(os.path.join(model_dir, 'metadata.json'), 'w') as f:
            json.dump(metadata, f, indent=2)
        
        print(f"‚úÖ Model kaydedildi: {model_dir}")
        return model_dir
    
    @classmethod
    def load(cls, model_dir: str) -> 'MalwareDetectionModel':
        """
        Modeli y√ºkle
        
        Args:
            model_dir: Model dizini
            
        Returns:
            Model instance
        """
        # Metadata
        with open(os.path.join(model_dir, 'metadata.json'), 'r') as f:
            metadata = json.load(f)
        
        instance = cls(
            model_type=metadata['model_type'],
            use_neural_network=metadata['use_neural_network']
        )
        
        # Classifier
        with open(os.path.join(model_dir, 'classifier.pkl'), 'rb') as f:
            instance.classifier = pickle.load(f)
        
        # Scaler
        with open(os.path.join(model_dir, 'scaler.pkl'), 'rb') as f:
            instance.scaler = pickle.load(f)
        
        # Neural Network
        nn_path = os.path.join(model_dir, 'neural_network.h5')
        if os.path.exists(nn_path) and TF_AVAILABLE:
            instance.neural_network = keras.models.load_model(nn_path)
        
        instance.is_trained = True
        
        print(f"‚úÖ Model y√ºklendi: {model_dir}")
        return instance


# Test
if __name__ == "__main__":
    if SKLEARN_AVAILABLE:
        print("üß™ Malware Detection Model Test\n")
        
        # Mock veri
        np.random.seed(42)
        X = np.random.rand(100, 5)
        y = np.random.randint(0, 2, 100)
        
        # Model
        model = MalwareDetectionModel(model_type='gradient_boosting')
        
        # Eƒüit
        results = model.train(X, y)
        
        # Tahmin
        pred = model.predict_single([0.5, 0.6, 0.3, 0.8, 0.2])
        print(f"\nüìä Tahmin: {pred}")
    else:
        print("‚ùå Test i√ßin scikit-learn gerekli!")
