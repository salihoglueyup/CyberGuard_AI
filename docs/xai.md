# ğŸ” Explainable AI (XAI) DokÃ¼mantasyonu

CyberGuard AI projesindeki Explainable AI Ã¶zellikleri - DetaylÄ± Rehber

---

## ğŸ“‹ Ä°Ã§indekiler

- [Genel BakÄ±ÅŸ](#genel-bakÄ±ÅŸ)
- [Neden XAI?](#neden-xai)
- [API Endpoints](#api-endpoints)
- [SHAP AÃ§Ä±klamalarÄ±](#shap-aÃ§Ä±klamalarÄ±)
- [LIME AÃ§Ä±klamalarÄ±](#lime-aÃ§Ä±klamalarÄ±)
- [Feature Importance](#feature-importance)
- [GÃ¶rselleÅŸtirmeler](#gÃ¶rselleÅŸtirmeler)
- [KullanÄ±m Ã–rnekleri](#kullanÄ±m-Ã¶rnekleri)
- [Best Practices](#best-practices)

---

## ğŸŒŸ Genel BakÄ±ÅŸ

XAI modÃ¼lÃ¼, makine Ã¶ÄŸrenmesi modellerinin kararlarÄ±nÄ± aÃ§Ä±klamak iÃ§in SHAP (SHapley Additive exPlanations) ve LIME (Local Interpretable Model-agnostic Explanations) yÃ¶ntemlerini kullanÄ±r.

### Desteklenen AÃ§Ä±klama YÃ¶ntemleri

| YÃ¶ntem | TÃ¼r | AÃ§Ä±klama |
|--------|-----|----------|
| **SHAP** | Global + Local | Shapley deÄŸerleri ile aÃ§Ä±klama |
| **LIME** | Local | Lokal yorumlanabilir model |
| **Feature Importance** | Global | Model bazlÄ± Ã¶nem sÄ±ralamasÄ± |
| **Permutation Importance** | Global | PermÃ¼tasyon tabanlÄ± Ã¶nem |

---

## ğŸ¯ Neden XAI?

### Siber GÃ¼venlikte Ã–nem

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    XAI'Ä±n FaydalarÄ±                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ğŸ” ÅEFFAFLÄ°K      â”‚ Model kararlarÄ±nÄ±n neden verildiÄŸini anlamaâ”‚
â”‚  ğŸ¤ GÃœVEN          â”‚ KullanÄ±cÄ±larÄ±n AI Ã¶nerilerine gÃ¼venmesi    â”‚
â”‚  ğŸ› DEBUG          â”‚ Model hatalarÄ±nÄ± tespit etmek              â”‚
â”‚  âš–ï¸ COMPLIANCE     â”‚ GDPR, KVKK gibi dÃ¼zenlemelere uyum         â”‚
â”‚  ğŸ“ EÄÄ°TÄ°M         â”‚ GÃ¼venlik analistlerini eÄŸitmek             â”‚
â”‚  âœ… VALÄ°DASYON     â”‚ Model davranÄ±ÅŸÄ±nÄ± doÄŸrulamak               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Yasal Gereksinimler

- **GDPR Article 22**: Automated decision-making, including profiling
- **KVKK Madde 11**: KiÅŸinin, kendisiyle ilgili otomatik iÅŸleme dayalÄ± kararlar hakkÄ±nda bilgi edinme hakkÄ±
- **ISO 27001**: Information security management

---

## ğŸ”Œ API Endpoints

### POST /api/xai/explain

Model tahminini aÃ§Ä±kla

**Request:**

```json
{
  "model_id": "best_cicids2017",
  "features": [0.1, 0.2, 0.3, ...],
  "num_features": 10,
  "method": "shap"
}
```

**Response:**

```json
{
  "success": true,
  "data": {
    "prediction": "DDoS",
    "confidence": 0.98,
    "explanation": {
      "method": "shap",
      "base_value": 0.12,
      "top_features": [
        {
          "feature": "Flow Duration",
          "value": 15234.5,
          "shap_value": 0.35,
          "contribution": "positive",
          "rank": 1
        },
        {
          "feature": "Total Fwd Packets",
          "value": 892,
          "shap_value": -0.12,
          "contribution": "negative",
          "rank": 2
        }
      ]
    },
    "feature_values": [...],
    "timestamp": "2026-01-10T12:00:00"
  }
}
```

### GET /api/xai/feature-importance/{model_id}

**Response:**

```json
{
  "success": true,
  "data": {
    "model_id": "best_cicids2017",
    "method": "mean_shap",
    "feature_importance": [
      {"feature": "Flow Duration", "importance": 0.15, "rank": 1},
      {"feature": "Total Fwd Packets", "importance": 0.12, "rank": 2},
      {"feature": "Fwd Packet Length Mean", "importance": 0.10, "rank": 3}
    ]
  }
}
```

### GET /api/xai/global-importance

TÃ¼m modeller iÃ§in ortalama feature importance

### GET /api/xai/explanation-methods

**Response:**

```json
{
  "success": true,
  "data": {
    "methods": [
      {
        "id": "shap",
        "name": "SHAP",
        "description": "SHapley Additive exPlanations",
        "type": "global_local",
        "pros": ["Teorik tutarlÄ±lÄ±k", "Global aÃ§Ä±klamalar"],
        "cons": ["YavaÅŸ hesaplama", "YÃ¼ksek bellek"]
      },
      {
        "id": "lime",
        "name": "LIME",
        "description": "Local Interpretable Model-agnostic Explanations",
        "type": "local",
        "pros": ["HÄ±zlÄ±", "Model-agnostik"],
        "cons": ["TutarsÄ±z olabilir", "Sadece lokal"]
      }
    ]
  }
}
```

---

## ğŸ“Š SHAP AÃ§Ä±klamalarÄ±

### Teorik Arka Plan

SHAP, oyun teorisinden gelen Shapley deÄŸerlerini kullanarak her Ã¶zelliÄŸin tahmine katkÄ±sÄ±nÄ± hesaplar.

**Shapley DeÄŸeri FormÃ¼lÃ¼:**

```
Ï†áµ¢ = Î£ [|S|! (n-|S|-1)! / n!] Ã— [f(S âˆª {i}) - f(S)]
```

### SHAP TÃ¼rleri

| TÃ¼r | KullanÄ±m | HÄ±z |
|-----|----------|-----|
| TreeSHAP | Tree-based modeller | âš¡ Ã‡ok HÄ±zlÄ± |
| DeepSHAP | Deep learning | âš¡ HÄ±zlÄ± |
| KernelSHAP | Herhangi model | ğŸ¢ YavaÅŸ |
| LinearSHAP | Lineer modeller | âš¡ Ã‡ok HÄ±zlÄ± |

### Python KullanÄ±mÄ±

```python
import shap

# Model yÃ¼kle
model = load_model("best_cicids2017")

# SHAP explainer oluÅŸtur
explainer = shap.TreeExplainer(model)  # veya DeepExplainer

# AÃ§Ä±klama Ã¼ret
shap_values = explainer.shap_values(X_test)

# Tek Ã¶rnek iÃ§in aÃ§Ä±klama
shap.force_plot(explainer.expected_value, shap_values[0], X_test[0])

# Ã–zet plot
shap.summary_plot(shap_values, X_test)
```

### SHAP GÃ¶rselleri

```
Force Plot (Tek Ã–rnek):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Base: 0.12                                                   â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚  Flow Duration   â”‚  Total Fwd Packets      â”‚  Final: 0.98    â”‚
â”‚  +0.35           â”‚  -0.12                   â”‚                  â”‚
â”‚  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ”‚â–’â–’â–’â–’â–’â–’                    â”‚                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Summary Plot (TÃ¼m Ã–rnekler):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Feature            â”‚ SHAP Value Impact                      â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
â”‚  Flow Duration      â”‚ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ High              â”‚
â”‚  Total Fwd Packets  â”‚ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘ Medium            â”‚
â”‚  Fwd Packet Length  â”‚ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ Low               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ‹ LIME AÃ§Ä±klamalarÄ±

### NasÄ±l Ã‡alÄ±ÅŸÄ±r?

1. Tahmin noktasÄ± Ã§evresinde perturbation samples oluÅŸtur
2. Her sample iÃ§in orijinal model tahmini al
3. Weighted linear model eÄŸit
4. Linear model katsayÄ±larÄ±nÄ± aÃ§Ä±klama olarak kullan

### Python KullanÄ±mÄ±

```python
from lime import lime_tabular

# LIME explainer oluÅŸtur
explainer = lime_tabular.LimeTabularExplainer(
    X_train,
    feature_names=feature_names,
    class_names=class_names,
    mode='classification'
)

# AÃ§Ä±klama Ã¼ret
explanation = explainer.explain_instance(
    X_test[0],
    model.predict_proba,
    num_features=10
)

# GÃ¶rselle
explanation.show_in_notebook()

# Liste olarak
print(explanation.as_list())
# [('Flow Duration > 1000', 0.25), ('Total Fwd Packets > 500', 0.18), ...]
```

### LIME vs SHAP

| Ã–zellik | SHAP | LIME |
|---------|------|------|
| Teorik TutarlÄ±lÄ±k | âœ… | âŒ |
| HÄ±z | ğŸ¢ | âš¡ |
| Global AÃ§Ä±klama | âœ… | âŒ |
| Model-Agnostik | âœ… | âœ… |
| Stabilite | âœ… | âš ï¸ |
| Bellek KullanÄ±mÄ± | YÃ¼ksek | DÃ¼ÅŸÃ¼k |

---

## ğŸ¯ Feature Importance

### Global Importance

TÃ¼m tahminlerde hangi Ã¶zelliklerin genel olarak Ã¶nemli olduÄŸunu gÃ¶sterir.

```python
# Random Forest feature importance
importance = model.feature_importances_
feature_importance = pd.DataFrame({
    'feature': feature_names,
    'importance': importance
}).sort_values('importance', ascending=False)
```

### Lokal Importance

Tek bir tahmin iÃ§in hangi Ã¶zelliklerin belirleyici olduÄŸunu gÃ¶sterir.

### CyberGuard AI'daki En Ã–nemli Ã–zellikler

| SÄ±ra | Ã–zellik | Ã–nemi | AÃ§Ä±klama |
|------|---------|-------|----------|
| 1 | Flow Duration | 15% | AkÄ±ÅŸ sÃ¼resi |
| 2 | Total Fwd Packets | 12% | Forward paket sayÄ±sÄ± |
| 3 | Fwd Packet Length Mean | 10% | Ortalama forward paket uzunluÄŸu |
| 4 | Bwd Packet Length Mean | 9% | Ortalama backward paket uzunluÄŸu |
| 5 | Flow Bytes/s | 8% | Saniye baÅŸÄ±na byte |

---

## ğŸ“ˆ GÃ¶rselleÅŸtirmeler

### Frontend GÃ¶rselleÅŸtirmeleri

```jsx
// XAIExplainer.jsx'te kullanÄ±m

// Bar Chart
{explanation.top_features.map(feature => (
  <div className="bar-container">
    <span>{feature.feature}</span>
    <div 
      className="bar"
      style={{ 
        width: `${Math.abs(feature.shap_value) * 100}%`,
        backgroundColor: feature.contribution === 'positive' ? 'green' : 'red'
      }}
    />
    <span>{feature.shap_value.toFixed(4)}</span>
  </div>
))}
```

### API ile GÃ¶rsel

```python
import requests
import matplotlib.pyplot as plt

# AÃ§Ä±klama al
response = requests.post("/api/xai/explain", json={
    "model_id": "best_cicids2017",
    "features": sample_features,
    "method": "shap"
})

data = response.json()["data"]["explanation"]["top_features"]

# Plot
features = [f["feature"] for f in data]
values = [f["shap_value"] for f in data]
colors = ['green' if v > 0 else 'red' for v in values]

plt.barh(features, values, color=colors)
plt.xlabel("SHAP Value")
plt.title("Feature Contributions")
plt.show()
```

---

## ğŸ’» KullanÄ±m Ã–rnekleri

### 1. SaldÄ±rÄ± AÃ§Ä±klamasÄ±

```python
# Bir saldÄ±rÄ± tahmini iÃ§in aÃ§Ä±klama
attack_sample = get_attack_sample("DDoS")

explanation = requests.post("/api/xai/explain", json={
    "model_id": "best_cicids2017",
    "features": attack_sample.tolist(),
    "method": "shap"
}).json()

print(f"Tahmin: {explanation['data']['prediction']}")
print(f"GÃ¼ven: {explanation['data']['confidence']:.2%}")
print("\nÃ–nemli FaktÃ¶rler:")
for f in explanation['data']['explanation']['top_features'][:5]:
    print(f"  {f['feature']}: {f['shap_value']:+.4f}")
```

### 2. Model KarÅŸÄ±laÅŸtÄ±rmasÄ±

```python
# Ä°ki model iÃ§in aynÄ± Ã¶rneÄŸin aÃ§Ä±klamasÄ±
models = ["lstm_model", "random_forest_model"]

for model_id in models:
    exp = requests.post("/api/xai/explain", json={
        "model_id": model_id,
        "features": sample.tolist(),
        "method": "shap"
    }).json()
    
    print(f"\n{model_id}:")
    print(f"Tahmin: {exp['data']['prediction']}")
```

### 3. Batch AÃ§Ä±klama

```python
# Birden fazla Ã¶rnek iÃ§in aÃ§Ä±klama
results = []
for sample in samples:
    exp = requests.post("/api/xai/explain", json={
        "model_id": "best_cicids2017",
        "features": sample.tolist(),
        "method": "lime"  # LIME daha hÄ±zlÄ±
    }).json()
    results.append(exp["data"])
```

---

## ğŸ“ Best Practices

### 1. YÃ¶ntem SeÃ§imi

| Senaryo | Ã–nerilen YÃ¶ntem |
|---------|-----------------|
| HÄ±zlÄ± aÃ§Ä±klama | LIME |
| DetaylÄ± analiz | SHAP |
| Tree-based model | TreeSHAP |
| Deep learning | DeepSHAP |
| Global gÃ¶rÃ¼nÃ¼m | SHAP Summary |

### 2. Performans Ä°yileÅŸtirmeleri

```python
# SHAP iÃ§in sample kullan
shap_values = explainer.shap_values(X_test[:100])  # Ä°lk 100 Ã¶rnek

# Background data limitle
explainer = shap.KernelExplainer(
    model.predict, 
    shap.sample(X_train, 100)  # 100 background sample
)
```

### 3. AÃ§Ä±klama Kalitesi

- En az 5-10 Ã¶zellik gÃ¶ster
- Pozitif/negatif katkÄ±larÄ± renklendir
- Ã–zellik deÄŸerlerini de gÃ¶ster
- GÃ¼ven aralÄ±ÄŸÄ± ekle

---

## ğŸ“š Referanslar

- [SHAP Paper](https://arxiv.org/abs/1705.07874) - Lundberg & Lee (2017)
- [LIME Paper](https://arxiv.org/abs/1602.04938) - Ribeiro et al. (2016)
- [Interpretable ML Book](https://christophm.github.io/interpretable-ml-book/)
- [SHAP Documentation](https://shap.readthedocs.io/)
- [LIME Documentation](https://lime-ml.readthedocs.io/)
