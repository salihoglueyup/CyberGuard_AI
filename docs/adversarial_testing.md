# âš”ï¸ Adversarial Testing DokÃ¼mantasyonu

Model gÃ¼venliÄŸi ve adversarial attack test sistemi - DetaylÄ± Rehber

---

## ğŸ“‹ Ä°Ã§indekiler

- [Genel BakÄ±ÅŸ](#genel-bakÄ±ÅŸ)
- [Neden Adversarial Testing?](#neden-adversarial-testing)
- [Desteklenen SaldÄ±rÄ± TÃ¼rleri](#desteklenen-saldÄ±rÄ±-tÃ¼rleri)
- [API Endpoints](#api-endpoints)
- [Robustness DeÄŸerlendirmesi](#robustness-deÄŸerlendirmesi)
- [Savunma YÃ¶ntemleri](#savunma-yÃ¶ntemleri)
- [KullanÄ±m Ã–rnekleri](#kullanÄ±m-Ã¶rnekleri)
- [Best Practices](#best-practices)

---

## ğŸŒŸ Genel BakÄ±ÅŸ

Adversarial Testing modÃ¼lÃ¼, ML modellerinin kasÄ±tlÄ± olarak tasarlanmÄ±ÅŸ saldÄ±rÄ±lara karÅŸÄ± dayanÄ±klÄ±lÄ±ÄŸÄ±nÄ± test eder.

### Adversarial Attack Nedir?

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   ADVERSARIAL ATTACK                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  Normal Input          Perturbation         Adversarial Input   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚  DDoS    â”‚    +     â”‚  noise   â”‚    =    â”‚  Normal  â”‚        â”‚
â”‚  â”‚  %99     â”‚          â”‚  Îµ=0.01  â”‚         â”‚  %95     â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚                                                                  â”‚
â”‚  Model gÃ¶rÃ¼nmez bir perturbation ile kandÄ±rÄ±lÄ±r!                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ¯ Neden Adversarial Testing?

### GÃ¼venlik Riskleri

| Risk | AÃ§Ä±klama | Etki |
|------|----------|------|
| **Evasion Attack** | SaldÄ±rÄ±yÄ± normal trafik gibi gÃ¶sterme | IDS bypass |
| **Poisoning Attack** | EÄŸitim verisini manipÃ¼le etme | Model bozulmasÄ± |
| **Model Stealing** | Model parametrelerini Ã§alma | IP kaybÄ± |
| **Inference Attack** | Hassas veri Ã§Ä±karÄ±mÄ± | Gizlilik ihlali |

### GerÃ§ek DÃ¼nya SenaryolarÄ±

1. **Malware evasion**: ZararlÄ± yazÄ±lÄ±mÄ± antivirÃ¼sten gizleme
2. **Spam bypass**: Spam filtresini atlama
3. **IDS evasion**: SaldÄ±rÄ± trafiÄŸini normal gÃ¶sterme
4. **Fraud masking**: Sahte iÅŸlemleri gizleme

---

## ğŸ¯ Desteklenen SaldÄ±rÄ± TÃ¼rleri

### 1. FGSM (Fast Gradient Sign Method)

**AÃ§Ä±klama**: Gradient yÃ¶nÃ¼nde tek adÄ±m perturbation

```python
# FGSM formÃ¼lÃ¼
x_adv = x + Îµ * sign(âˆ‡_x L(Î¸, x, y))
```

**Ã–zellikler:**

| Ã–zellik | DeÄŸer |
|---------|-------|
| HÄ±z | âš¡ Ã‡ok HÄ±zlÄ± |
| Etkililik | â˜…â˜…â˜…â˜†â˜† |
| AlgÄ±lanabilirlik | Orta |
| Parametre | Îµ (epsilon) |

**KullanÄ±m:**

```python
from art.attacks.evasion import FastGradientMethod

attack = FastGradientMethod(estimator=classifier, eps=0.1)
x_adv = attack.generate(x=X_test)
```

### 2. PGD (Projected Gradient Descent)

**AÃ§Ä±klama**: Ä°teratif gradient-based saldÄ±rÄ±

```python
# PGD algoritmasÄ±
for i in range(num_iterations):
    x_adv = x_adv + Î± * sign(âˆ‡_x L(Î¸, x_adv, y))
    x_adv = clip(x_adv, x - Îµ, x + Îµ)
```

**Ã–zellikler:**

| Ã–zellik | DeÄŸer |
|---------|-------|
| HÄ±z | âš¡ Orta |
| Etkililik | â˜…â˜…â˜…â˜…â˜† |
| AlgÄ±lanabilirlik | DÃ¼ÅŸÃ¼k |
| Parametreler | Îµ, Î±, iterations |

**KullanÄ±m:**

```python
from art.attacks.evasion import ProjectedGradientDescent

attack = ProjectedGradientDescent(
    estimator=classifier,
    eps=0.1,
    eps_step=0.01,
    max_iter=40
)
x_adv = attack.generate(x=X_test)
```

### 3. C&W (Carlini & Wagner)

**AÃ§Ä±klama**: Optimizasyon tabanlÄ± gÃ¼Ã§lÃ¼ saldÄ±rÄ±

```python
# C&W objective
minimize ||Î´||_p + c * f(x + Î´)
subject to x + Î´ âˆˆ [0, 1]^n
```

**Ã–zellikler:**

| Ã–zellik | DeÄŸer |
|---------|-------|
| HÄ±z | ğŸ¢ YavaÅŸ |
| Etkililik | â˜…â˜…â˜…â˜…â˜… |
| AlgÄ±lanabilirlik | Ã‡ok DÃ¼ÅŸÃ¼k |
| Parametreler | c, Îº, learning_rate |

**KullanÄ±m:**

```python
from art.attacks.evasion import CarliniL2Method

attack = CarliniL2Method(
    classifier=classifier,
    targeted=False,
    max_iter=100
)
x_adv = attack.generate(x=X_test)
```

### 4. DeepFool

**AÃ§Ä±klama**: Minimum perturbation bulma

**Ã–zellikler:**

| Ã–zellik | DeÄŸer |
|---------|-------|
| HÄ±z | âš¡ Orta |
| Etkililik | â˜…â˜…â˜…â˜…â˜† |
| AlgÄ±lanabilirlik | Ã‡ok DÃ¼ÅŸÃ¼k |

### 5. JSMA (Jacobian-based Saliency Map Attack)

**AÃ§Ä±klama**: Saliency map tabanlÄ± hedefli saldÄ±rÄ±

**Ã–zellikler:**

| Ã–zellik | DeÄŸer |
|---------|-------|
| HÄ±z | ğŸ¢ YavaÅŸ |
| Etkililik | â˜…â˜…â˜…â˜†â˜† |
| Sparse perturbation | âœ… |

### SaldÄ±rÄ± KarÅŸÄ±laÅŸtÄ±rmasÄ±

```
            HÄ±z                    Etkililik
FGSM        â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘
PGD         â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘
C&W         â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
DeepFool    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘
JSMA        â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘
```

---

## ğŸ”Œ API Endpoints

### GET /api/adversarial/attack-types

```json
{
  "success": true,
  "data": {
    "attack_types": [
      {
        "id": "fgsm",
        "name": "Fast Gradient Sign Method",
        "description": "Single-step gradient attack",
        "speed": "very_fast",
        "effectiveness": "medium",
        "parameters": ["epsilon"]
      }
    ]
  }
}
```

### POST /api/adversarial/test

Model robustness testi Ã§alÄ±ÅŸtÄ±r

**Request:**

```json
{
  "model_id": "best_cicids2017",
  "attack_type": "fgsm",
  "epsilon": 0.1,
  "iterations": 40,
  "sample_size": 1000,
  "targeted": false
}
```

**Response:**

```json
{
  "success": true,
  "data": {
    "test_id": "ADV-20260110-abc123",
    "model_id": "best_cicids2017",
    "attack_type": "fgsm",
    "results": {
      "original_accuracy": 99.88,
      "accuracy_under_attack": 85.42,
      "accuracy_drop": 14.46,
      "attack_success_rate": 14.46,
      "avg_perturbation": 0.087,
      "max_perturbation": 0.1
    },
    "verdict": "moderately_robust",
    "recommendations": [
      "Consider adversarial training",
      "Lower epsilon tolerance recommended"
    ]
  }
}
```

### POST /api/adversarial/simulate

Adversarial Ã¶rnek oluÅŸtur

**Request:**

```json
{
  "model_id": "best_cicids2017",
  "original_features": [0.1, 0.2, ...],
  "attack_type": "pgd",
  "target_class": null
}
```

**Response:**

```json
{
  "success": true,
  "data": {
    "original_prediction": "DDoS",
    "adversarial_prediction": "Normal",
    "original_features": [...],
    "adversarial_features": [...],
    "perturbation": [...],
    "l2_distance": 0.0234,
    "linf_distance": 0.0087
  }
}
```

### GET /api/adversarial/robustness/{model_id}

```json
{
  "success": true,
  "data": {
    "model_id": "best_cicids2017",
    "robustness_score": 78,
    "tests": {
      "fgsm_0.01": {"accuracy": 98.2, "status": "pass"},
      "fgsm_0.1": {"accuracy": 85.4, "status": "warning"},
      "pgd_0.1": {"accuracy": 82.1, "status": "warning"},
      "cw": {"accuracy": 75.8, "status": "fail"}
    },
    "overall_verdict": "moderately_robust"
  }
}
```

### GET /api/adversarial/defense-methods

```json
{
  "success": true,
  "data": {
    "defense_methods": [
      {
        "id": "adversarial_training",
        "name": "Adversarial Training",
        "description": "Train with adversarial examples",
        "effectiveness": "high",
        "overhead": "medium"
      }
    ]
  }
}
```

---

## ğŸ“Š Robustness DeÄŸerlendirmesi

### Robustness Skoru (0-100)

| Skor | Derece | AÃ§Ä±klama |
|------|--------|----------|
| 90-100 | A | Ã‡ok Robust |
| 80-89 | B | Robust |
| 70-79 | C | Orta |
| 60-69 | D | ZayÄ±f |
| 0-59 | F | Kritik Risk |

### Test Metrikleri

| Metrik | AÃ§Ä±klama |
|--------|----------|
| Accuracy under attack | SaldÄ±rÄ± altÄ±nda doÄŸruluk |
| Attack success rate | SaldÄ±rÄ± baÅŸarÄ± oranÄ± |
| Average perturbation | Ortalama perturbation miktarÄ± |
| Certified radius | Garantili gÃ¼venli yarÄ±Ã§ap |

---

## ğŸ›¡ï¸ Savunma YÃ¶ntemleri

### 1. Adversarial Training

**AÃ§Ä±klama**: Adversarial Ã¶rneklerle model eÄŸitimi

```python
# Adversarial training
for epoch in range(epochs):
    for x, y in train_loader:
        # Normal eÄŸitim
        loss_normal = criterion(model(x), y)
        
        # Adversarial Ã¶rnek Ã¼ret
        x_adv = generate_adversarial(x, y)
        loss_adv = criterion(model(x_adv), y)
        
        # Combine losses
        loss = loss_normal + Î± * loss_adv
        loss.backward()
        optimizer.step()
```

**Etkililik**: â˜…â˜…â˜…â˜…â˜…

### 2. Input Preprocessing

**AÃ§Ä±klama**: GiriÅŸ verilerini temizleme

```python
# JPEG compression
from torchvision import transforms
preprocess = transforms.Compose([
    transforms.Lambda(lambda x: jpeg_compress(x, quality=75)),
    transforms.GaussianBlur(kernel_size=3)
])
```

**Etkililik**: â˜…â˜…â˜…â˜†â˜†

### 3. Defensive Distillation

**AÃ§Ä±klama**: Model Ã§Ä±ktÄ±larÄ±nÄ± yumuÅŸatma

```python
# Temperature scaling
def softmax_with_temperature(logits, T):
    return F.softmax(logits / T, dim=1)

# Train with high temperature
teacher_output = softmax_with_temperature(teacher_logits, T=20)
```

**Etkililik**: â˜…â˜…â˜…â˜…â˜†

### 4. Gradient Masking

**AÃ§Ä±klama**: Gradient bilgisini gizleme

**UyarÄ±**: âš ï¸ GÃ¼venli deÄŸil, bypass edilebilir!

### 5. Ensemble Methods

**AÃ§Ä±klama**: Birden fazla model kullanma

```python
# Ensemble voting
predictions = []
for model in ensemble:
    predictions.append(model.predict(x))
final_prediction = majority_vote(predictions)
```

**Etkililik**: â˜…â˜…â˜…â˜…â˜†

---

## ğŸ’» KullanÄ±m Ã–rnekleri

### 1. Temel Robustness Testi

```python
import requests

# Test Ã§alÄ±ÅŸtÄ±r
response = requests.post("/api/adversarial/test", json={
    "model_id": "best_cicids2017",
    "attack_type": "fgsm",
    "epsilon": 0.1,
    "sample_size": 1000
})

result = response.json()["data"]
print(f"Original Accuracy: {result['results']['original_accuracy']}%")
print(f"Under Attack: {result['results']['accuracy_under_attack']}%")
print(f"Verdict: {result['verdict']}")
```

### 2. Epsilon Sweep

```python
# FarklÄ± epsilon deÄŸerleri ile test
epsilons = [0.01, 0.05, 0.1, 0.2, 0.3]
results = []

for eps in epsilons:
    resp = requests.post("/api/adversarial/test", json={
        "model_id": "best_cicids2017",
        "attack_type": "fgsm",
        "epsilon": eps
    })
    results.append({
        "epsilon": eps,
        "accuracy": resp.json()["data"]["results"]["accuracy_under_attack"]
    })

# Plot
import matplotlib.pyplot as plt
plt.plot([r["epsilon"] for r in results], [r["accuracy"] for r in results])
plt.xlabel("Epsilon")
plt.ylabel("Accuracy (%)")
plt.title("Robustness vs Perturbation Size")
plt.show()
```

### 3. Adversarial Ã–rnek GÃ¶rselleÅŸtirme

```python
# Adversarial Ã¶rnek oluÅŸtur
response = requests.post("/api/adversarial/simulate", json={
    "model_id": "best_cicids2017",
    "original_features": sample.tolist(),
    "attack_type": "pgd"
})

data = response.json()["data"]
print(f"Original: {data['original_prediction']}")
print(f"Adversarial: {data['adversarial_prediction']}")
print(f"L2 Distance: {data['l2_distance']:.6f}")
```

---

## ğŸ“ Best Practices

### 1. Test Stratejisi

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. BaÅŸlangÄ±Ã§: FGSM ile hÄ±zlÄ± test (Îµ=0.01, 0.05, 0.1)          â”‚
â”‚ 2. Derinlemesine: PGD ile iteratif test                         â”‚
â”‚ 3. En kÃ¶tÃ¼ durum: C&W ile gÃ¼Ã§lÃ¼ saldÄ±rÄ±                         â”‚
â”‚ 4. SonuÃ§: Robustness raporu oluÅŸtur                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2. Kabul Kriterleri

| SaldÄ±rÄ± | Min Accuracy | Epsilon |
|---------|--------------|---------|
| FGSM | 90% | 0.1 |
| PGD | 85% | 0.1 |
| C&W | 75% | - |

### 3. Continuous Testing

```yaml
# CI/CD pipeline'da adversarial test
adversarial_test:
  - fgsm_eps_0.05: min_accuracy: 95%
  - pgd_eps_0.1: min_accuracy: 85%
  - notify_on_failure: true
```

---

## ğŸ“š Referanslar

- [Explaining and Harnessing Adversarial Examples](https://arxiv.org/abs/1412.6572) - Goodfellow et al.
- [Towards Evaluating the Robustness of Neural Networks](https://arxiv.org/abs/1608.04644) - Carlini & Wagner
- [Adversarial examples in the physical world](https://arxiv.org/abs/1607.02533)
- [Adversarial Robustness Toolbox (ART)](https://github.com/Trusted-AI/adversarial-robustness-toolbox)
- [CleverHans Library](https://github.com/cleverhans-lab/cleverhans)
