# ğŸ§  Machine Learning Models DokÃ¼mantasyonu

CyberGuard AI'da kullanÄ±lan tÃ¼m makine Ã¶ÄŸrenmesi modelleri

---

## ğŸ“‹ Ä°Ã§indekiler

- [Model Mimarisi](#model-mimarisi)
- [SSA-LSTMIDS (Ana Model)](#ssa-lstmids-ana-model)
- [Desteklenen Modeller](#desteklenen-modeller)
- [Model PerformanslarÄ±](#model-performanslarÄ±)
- [Model EÄŸitimi](#model-eÄŸitimi)
- [Model KullanÄ±mÄ±](#model-kullanÄ±mÄ±)

---

## ğŸ—ï¸ Model Mimarisi

### SSA-LSTMIDS Mimarisi

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      INPUT LAYER                             â”‚
â”‚                    (78 features)                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   CONV1D BLOCK 1                             â”‚
â”‚  Conv1D(30, kernel=3) â†’ BatchNorm â†’ ReLU â†’ MaxPool(2)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   CONV1D BLOCK 2                             â”‚
â”‚  Conv1D(60, kernel=3) â†’ BatchNorm â†’ ReLU â†’ MaxPool(2)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     LSTM LAYER                               â”‚
â”‚           LSTM(120 units, return_sequences=True)             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   ATTENTION LAYER                            â”‚
â”‚            MultiHeadAttention(num_heads=4)                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    DENSE LAYERS                              â”‚
â”‚      Dense(512) â†’ Dropout(0.2) â†’ Dense(256) â†’ Dropout(0.2)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   OUTPUT LAYER                               â”‚
â”‚              Dense(num_classes, softmax)                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ¯ SSA-LSTMIDS (Ana Model)

### Genel Bilgiler

| Ã–zellik | DeÄŸer |
|---------|-------|
| **Model AdÄ±** | SSA-LSTMIDS (Sparrow Search Algorithm - LSTM IDS) |
| **Kaynak Makale** | "An optimized LSTM-based deep learning model for anomaly network intrusion detection" |
| **YayÄ±n** | Scientific Reports, 2025 |
| **Optimizasyon** | SSA (Sparrow Search Algorithm) |

### SSA Optimizasyonu

SSA (Sparrow Search Algorithm), serÃ§elerin yiyecek arama davranÄ±ÅŸÄ±ndan ilham alan metaheuristik bir optimizasyon algoritmasÄ±dÄ±r.

**Optimize Edilen Hiperparametreler:**

- Conv1D filter sayÄ±sÄ± (30)
- LSTM unit sayÄ±sÄ± (120)
- Dense layer units (512)
- Dropout oranÄ± (0.2)
- Epoch sayÄ±sÄ± (300)
- Batch size (120)

### Performans SonuÃ§larÄ±

| Dataset | Accuracy | Precision | Recall | F1-Score |
|---------|----------|-----------|--------|----------|
| **NSL-KDD** | 99.36% | 99.37% | 99.36% | 99.36% |
| **CICIDS2017** | 99.88% | 99.89% | 99.88% | 99.88% |
| **BoT-IoT** | 99.99% | 99.99% | 99.99% | 99.99% |

---

## ğŸ“š Desteklenen Modeller

### 1. Deep Learning Modelleri

#### LSTM (Long Short-Term Memory)

```python
# Basit LSTM
model = keras.Sequential([
    keras.layers.LSTM(128, return_sequences=True),
    keras.layers.LSTM(64),
    keras.layers.Dense(num_classes, activation='softmax')
])
```

- **KullanÄ±m**: Temporal pattern recognition
- **Accuracy**: ~96-98%

#### BiLSTM (Bidirectional LSTM)

```python
# Bidirectional LSTM
model = keras.Sequential([
    keras.layers.Bidirectional(keras.layers.LSTM(128, return_sequences=True)),
    keras.layers.Bidirectional(keras.layers.LSTM(64)),
    keras.layers.Dense(num_classes, activation='softmax')
])
```

- **KullanÄ±m**: Forward + backward context
- **Accuracy**: ~97-99%

#### CNN-LSTM Hybrid

```python
# CNN + LSTM
model = keras.Sequential([
    keras.layers.Conv1D(64, 3, activation='relu'),
    keras.layers.MaxPooling1D(2),
    keras.layers.LSTM(128),
    keras.layers.Dense(num_classes, activation='softmax')
])
```

- **KullanÄ±m**: Feature extraction + sequence learning
- **Accuracy**: ~98-99.5%

#### Transformer

```python
# Attention-based model
inputs = keras.layers.Input(shape=(timesteps, features))
x = keras.layers.MultiHeadAttention(num_heads=4, key_dim=64)(inputs, inputs)
x = keras.layers.GlobalAveragePooling1D()(x)
outputs = keras.layers.Dense(num_classes, activation='softmax')(x)
```

- **KullanÄ±m**: Self-attention mechanisms
- **Accuracy**: ~97-99%

### 2. Traditional ML Modelleri

#### Random Forest

```python
from sklearn.ensemble import RandomForestClassifier

model = RandomForestClassifier(
    n_estimators=200,
    max_depth=20,
    random_state=42
)
```

- **KullanÄ±m**: Baseline, hÄ±zlÄ± inference
- **Accuracy**: ~92-96%

#### XGBoost

```python
import xgboost as xgb

model = xgb.XGBClassifier(
    n_estimators=300,
    max_depth=10,
    learning_rate=0.1
)
```

- **KullanÄ±m**: Gradient boosting
- **Accuracy**: ~94-97%

#### Support Vector Machine

```python
from sklearn.svm import SVC

model = SVC(
    kernel='rbf',
    C=1.0,
    gamma='auto'
)
```

- **KullanÄ±m**: Linear/non-linear classification
- **Accuracy**: ~90-94%

---

## ğŸ“Š Model PerformanslarÄ±

### Dataset BazÄ±nda KarÅŸÄ±laÅŸtÄ±rma

#### NSL-KDD Dataset

| Model | Accuracy | Precision | Recall | F1-Score | Training Time |
|-------|----------|-----------|--------|----------|---------------|
| SSA-LSTMIDS | **99.36%** | 99.37% | 99.36% | 99.36% | 45 min |
| BiLSTM | 98.52% | 98.54% | 98.52% | 98.53% | 35 min |
| CNN-LSTM | 98.21% | 98.23% | 98.21% | 98.22% | 40 min |
| Random Forest | 96.15% | 96.18% | 96.15% | 96.16% | 5 min |
| XGBoost | 95.82% | 95.85% | 95.82% | 95.83% | 8 min |

#### CICIDS2017 Dataset

| Model | Accuracy | Precision | Recall | F1-Score | Training Time |
|-------|----------|-----------|--------|----------|---------------|
| SSA-LSTMIDS | **99.88%** | 99.89% | 99.88% | 99.88% | 2 hours |
| BiLSTM | 99.12% | 99.14% | 99.12% | 99.13% | 1.5 hours |
| CNN-LSTM | 98.95% | 98.97% | 98.95% | 98.96% | 1.8 hours |
| Random Forest | 97.45% | 97.48% | 97.45% | 97.46% | 20 min |
| XGBoost | 97.21% | 97.24% | 97.21% | 97.22% | 30 min |

#### BoT-IoT Dataset

| Model | Accuracy | Precision | Recall | F1-Score | Training Time |
|-------|----------|-----------|--------|----------|---------------|
| SSA-LSTMIDS | **99.99%** | 99.99% | 99.99% | 99.99% | 4 hours |
| BiLSTM | 99.85% | 99.86% | 99.85% | 99.85% | 3 hours |
| CNN-LSTM | 99.78% | 99.79% | 99.78% | 99.78% | 3.5 hours |
| Random Forest | 99.12% | 99.15% | 99.12% | 99.13% | 45 min |
| XGBoost | 99.05% | 99.08% | 99.05% | 99.06% | 1 hour |

---

## ğŸ”§ Model EÄŸitimi

### EÄŸitim Scripti

```bash
# Full training pipeline
python scripts/train_cicids_full_ssa.py

# Specific dataset
python scripts/train_nsl_kdd.py
python scripts/train_botiot.py

# Fine-tuning
python scripts/finetune_deep_ssa.py
```

### EÄŸitim Parametreleri

```python
# Optimum parametreler
training_config = {
    'epochs': 300,
    'batch_size': 120,
    'learning_rate': 0.001,
    'optimizer': 'adam',
    'loss': 'sparse_categorical_crossentropy',
    'early_stopping_patience': 10,
    'reduce_lr_patience': 5,
    'validation_split': 0.2
}
```

### Data Augmentation

```python
# SMOTE for imbalanced classes
from imblearn.over_sampling import SMOTE

smote = SMOTE(random_state=42)
X_resampled, y_resampled = smote.fit_resample(X_train, y_train)
```

---

## ğŸ’» Model KullanÄ±mÄ±

### Python API

```python
from src.models.predictor import AttackPredictor

# Model yÃ¼kle
predictor = AttackPredictor()
predictor.load_models()

# Tek tahmin
result = predictor.predict_single(features)
print(f"Attack Type: {result['predicted_type']}")
print(f"Confidence: {result['confidence']:.2%}")

# Toplu tahmin
results = predictor.predict_batch(features_list)
```

### REST API

```bash
# Tahmin endpoint'i
curl -X POST http://localhost:8000/api/prediction/predict \
  -H "Content-Type: application/json" \
  -d '{"features": [0.1, 0.2, ...], "model_id": "best_cicids2017"}'
```

### Response Format

```json
{
  "success": true,
  "data": {
    "predicted_type": "DDoS",
    "confidence": 0.9876,
    "probabilities": {
      "Normal": 0.0012,
      "DDoS": 0.9876,
      "PortScan": 0.0089,
      "BruteForce": 0.0023
    },
    "risk_level": "critical"
  }
}
```

---

## ğŸ“ Model DosyalarÄ±

```
models/
â”œâ”€â”€ production/
â”‚   â”œâ”€â”€ best_cicids2017_model.h5
â”‚   â”œâ”€â”€ best_nslkdd_model.h5
â”‚   â””â”€â”€ best_botiot_model.h5
â”œâ”€â”€ experimental/
â”‚   â”œâ”€â”€ transformer_v1.h5
â”‚   â””â”€â”€ bilstm_attention.h5
â”œâ”€â”€ archived/
â”‚   â””â”€â”€ old_models/
â”œâ”€â”€ scalers/
â”‚   â”œâ”€â”€ cicids2017_scaler.pkl
â”‚   â”œâ”€â”€ nslkdd_scaler.pkl
â”‚   â””â”€â”€ botiot_scaler.pkl
â””â”€â”€ model_registry.json
```

---

## ğŸ“ Referanslar

- [An optimized LSTM-based deep learning model](https://doi.org/10.1038/s41598-025-85248-z)
- [NSL-KDD Dataset](https://www.unb.ca/cic/datasets/nsl.html)
- [CICIDS2017 Dataset](https://www.unb.ca/cic/datasets/ids-2017.html)
- [BoT-IoT Dataset](https://research.unsw.edu.au/projects/bot-iot-dataset)
